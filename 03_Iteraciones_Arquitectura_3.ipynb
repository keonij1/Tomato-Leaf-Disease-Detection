{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **EVALUACION DE 4 MODIFICACIONES A LA ARQUITECTURA # 3**\n",
        "\n"
      ],
      "metadata": {
        "id": "ETRR4_2CeOKp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdw9xCfvICU-"
      },
      "source": [
        "### **Exploración de datos**\n",
        "\n",
        "Cargamos todos los recursos y procesamos las imagenes. Estos procesos estan descritos a detalle en el archivo ***01 - Exploración y preprocesado de datos.ipynb***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvWdGs_XNkWb",
        "outputId": "68859fc3-c5e0-4865-e71c-c77771a7c120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (3.1.31)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython) (4.0.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n",
            "El repositorio ya ha sido clonado anteriormente.\n",
            "Los datos han sido procesados exitosamentes y esta estan listos para ser usados\n"
          ]
        }
      ],
      "source": [
        "!pip install gitpython\n",
        "import git\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# URL del repositorio de GitHub\n",
        "repo_url = 'https://github.com/keonij1/Tomato-Leaf-Disease-Detection'\n",
        "# Directorio de destino para clonar el repositorio\n",
        "destination_folder = '/Data'\n",
        "# Verificar si el directorio de destino ya existe\n",
        "if not os.path.exists(destination_folder):\n",
        "    # Clonar el repositorio si el directorio no existe\n",
        "    git.Repo.clone_from(repo_url, destination_folder)\n",
        "else:\n",
        "    print(\"El repositorio ya ha sido clonado anteriormente.\")\n",
        "\n",
        "# Directorio donde se clonó el repositorio\n",
        "destination_folder = '/Data'\n",
        "repo_dir = os.path.join(destination_folder, 'Data')\n",
        "# Directorio de imágenes\n",
        "images_dir = os.path.join(repo_dir, 'train')\n",
        "# Directorio raíz que contiene las 10 carpetas\n",
        "datos_graficar = images_dir\n",
        "# Obtener la lista de carpetas dentro del directorio raíz\n",
        "carpetas = os.listdir(datos_graficar)\n",
        "EPOCHS = 25  # Número de épocas para entrenamiento del modelo\n",
        "INIT_LR = 1e-3  # Tasa de aprendizaje inicial del modelo\n",
        "BS = 32  # Tamaño del lote (batch size)\n",
        "default_image_size = tuple((256, 256))  # Tamaño predeterminado de las imágenes (ancho, alto)\n",
        "image_size = 0  # Tamaño de las imágenes utilizadas en el proceso\n",
        "directory_root = repo_dir  # Ruta del directorio raíz donde se encuentran los datos o imágenes\n",
        "width = 256  # Ancho de las imágenes\n",
        "height = 256  # Alto de las imágenes\n",
        "depth = 3  # Profundidad de las imágenes (número de canales, en este caso 3 para RGB)\n",
        "\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        # Lee la imagen utilizando cv2.imread()\n",
        "        image = cv2.imread(image_dir)\n",
        "        # Verifica si la imagen se ha leído correctamente\n",
        "        if image is not None:\n",
        "            # Redimensiona la imagen a un tamaño específico\n",
        "            image = cv2.resize(image, default_image_size)\n",
        "            # Convierte la imagen en una matriz numpy utilizando img_to_array()\n",
        "            return img_to_array(image)\n",
        "        else:\n",
        "            # Devuelve una matriz vacía si la imagen no se ha leído correctamente\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        # Captura cualquier excepción que ocurra y muestra un mensaje de error\n",
        "        print(f\"Error: {e}\")\n",
        "        # Devuelve None en caso de error\n",
        "        return None\n",
        "\n",
        "image_list, label_list = [], []  # Listas vacías para almacenar las imágenes y las etiquetas correspondientes\n",
        "try:\n",
        "    root_dir = listdir(directory_root)  # Obtener una lista de los directorios en el directorio raíz\n",
        "    for directory in root_dir:\n",
        "        if directory == \".DS_Store\":  # Eliminar el archivo .DS_Store si está presente\n",
        "            root_dir.remove(directory)\n",
        "    for plant_folder in root_dir:\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")  # Obtener una lista de las carpetas de enfermedades de las plantas en el directorio de la planta actual\n",
        "        for disease_folder in plant_disease_folder_list:\n",
        "            if disease_folder == \".DS_Store\":  # Eliminar el archivo .DS_Store si está presente\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")  # Obtener una lista de las imágenes en la carpeta de enfermedades de plantas actual\n",
        "            for single_plant_disease_image in plant_disease_image_list:\n",
        "                if single_plant_disease_image == \".DS_Store\":  # Eliminar el archivo .DS_Store si está presente\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "            for image in plant_disease_image_list[:200]:  # Iterar sobre las primeras 200 imágenes de la lista de imágenes de enfermedades de plantas\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"  # Directorio de la imagen actual\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:  # Verificar si el archivo es una imagen JPG\n",
        "                    image_list.append(convert_image_to_array(image_directory))  # Convertir la imagen a un array y agregarla a la lista de imágenes\n",
        "                    label_list.append(plant_disease_folder)  # Agregar la etiqueta de la enfermedad de la planta a la lista de etiquetas\n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")\n",
        "\n",
        "image_size = len(image_list)  # Tamaño de la lista de imágenes\n",
        "label_binarizer = LabelBinarizer()  # Inicializar un objeto LabelBinarizer para codificar las etiquetas\n",
        "image_labels = label_binarizer.fit_transform(label_list)  # Codificar las etiquetas de las imágenes\n",
        "pickle.dump(label_binarizer, open('label_transform.pkl', 'wb'))  # Guardar el objeto LabelBinarizer en un archivo\n",
        "n_classes = len(label_binarizer.classes_)  # Número de clases en el conjunto de datos\n",
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0  # Convierte la lista de imágenes en un arreglo de NumPy y normaliza los valores de píxeles entre 0 y 1\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state=42)  # Divide los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2,\n",
        "    zoom_range=0.2,horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "print(\"Los datos han sido procesados exitosamentes y esta estan listos para ser usados!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x02iMkpdICVE"
      },
      "source": [
        "###  **ARQUITECTURA 3**\n",
        "\n",
        "Sobre esta arquitectura se realizaran 4 iteraciones ,en las cuales se realizaran diferentes modificaciones a la arquitectura\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOe0vbzPgPYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f6ce4c-0853-4483-c629-e82ab074f21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256, 256, 16)      0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 16)     64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 16)      2320      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 256, 256, 16)      0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256, 256, 16)     64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 128, 16)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128, 128, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 32)      9248      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128, 128, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16777472  \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,854,042\n",
            "Trainable params: 16,853,082\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar el resumen del modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jugq1oPHidsc"
      },
      "source": [
        "###  **ITERACION # 1**\n",
        "\n",
        "En esta iteracion se propone aumentar el número de filtros en las primeras 3 capas convolucionales. En este caso se duplicara el número de filtro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Qw84kdi6-G"
      },
      "outputs": [],
      "source": [
        "# Crear el modelo\n",
        "model = Sequential()\n",
        "\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Resumen del modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR4VXN6JkLMB"
      },
      "outputs": [],
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuIEvzp1kXqS"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'bo-', label='Training accuracy', markersize=4)\n",
        "plt.plot(epochs, val_acc, 'r*-', label='Validation accuracy', markersize=4)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "# Annotate the points with their values for accuracy\n",
        "for ep, vac in zip(epochs, val_acc):\n",
        "    plt.annotate(f'{vac:.3f}', xy=(ep, vac), xytext=(ep, vac - 0.04), ha='center', color='r')\n",
        "\n",
        "# Train and validation loss\n",
        "plt.figure()  # Create a new figure for loss plot\n",
        "plt.plot(epochs, loss, 'bo-', label='Training loss', markersize=4)\n",
        "plt.plot(epochs, val_loss, 'r*-', label='Validation loss', markersize=4)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "#plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Calculando la precision\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en la validacion: {scores[1]*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuQuhVw0jLiQ"
      },
      "source": [
        "###  **ITERACION # 2**\n",
        "\n",
        "En esta iteracion se propone cambiar el tamaño del kernel en las primeras 3 capas convolucionales. En es te caso se usara (5, 5) en lugar de (3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLXh4R-mjNA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2217b085-15bb-4c95-a471-62345f3f3a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 256, 256, 32)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 256, 256, 32)      0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 256, 256, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 128, 128, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 128, 128, 64)      18496     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 64, 64, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 262144)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               134218240 \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,335,114\n",
            "Trainable params: 134,335,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "\n",
        "model.add(Conv2D(32, (5, 5), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar el resumen del modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_RGvnnokPQE"
      },
      "outputs": [],
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-btKSDRkawZ"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'bo-', label='Training accuracy', markersize=4)\n",
        "plt.plot(epochs, val_acc, 'r*-', label='Validation accuracy', markersize=4)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "# Annotate the points with their values for accuracy\n",
        "for ep, vac in zip(epochs, val_acc):\n",
        "    plt.annotate(f'{vac:.3f}', xy=(ep, vac), xytext=(ep, vac - 0.04), ha='center', color='r')\n",
        "\n",
        "# Train and validation loss\n",
        "plt.figure()  # Create a new figure for loss plot\n",
        "plt.plot(epochs, loss, 'bo-', label='Training loss', markersize=4)\n",
        "plt.plot(epochs, val_loss, 'r*-', label='Validation loss', markersize=4)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "#plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Calculando la precision\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en la validacion: {scores[1]*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJoXmfs7jafT"
      },
      "source": [
        "###  **ITERACION # 3**\n",
        "\n",
        "En esta iteracion se propone agregar capas de normalización por lotes (Batch Normalization) después de las capas de convolución. Esto con el fin de intentar ayudar a estabilizar el entrenamiento y acelerar la convergencia del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QOIQQgmjaPZ"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar el resumen del modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxBnACFVkQKz"
      },
      "outputs": [],
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hGZ58XIkbq_"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'bo-', label='Training accuracy', markersize=4)\n",
        "plt.plot(epochs, val_acc, 'r*-', label='Validation accuracy', markersize=4)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "# Annotate the points with their values for accuracy\n",
        "for ep, vac in zip(epochs, val_acc):\n",
        "    plt.annotate(f'{vac:.3f}', xy=(ep, vac), xytext=(ep, vac - 0.04), ha='center', color='r')\n",
        "\n",
        "# Train and validation loss\n",
        "plt.figure()  # Create a new figure for loss plot\n",
        "plt.plot(epochs, loss, 'bo-', label='Training loss', markersize=4)\n",
        "plt.plot(epochs, val_loss, 'r*-', label='Validation loss', markersize=4)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "#plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Calculando la precision\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en la validacion: {scores[1]*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **ITERACION # 4**\n",
        "\n",
        "En esta iteracion se propone agregar una capa de regularización L2 (Weight Decay) a las capas totalmente conectadas (Dense) para penalizar los valores de los pesos grandes y reducir el sobreajuste"
      ],
      "metadata": {
        "id": "HTKF-s3FnXYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes, kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar el resumen del modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YSygWDY1nmDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ],
      "metadata": {
        "id": "-UEqa-Onnnuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'bo-', label='Training accuracy', markersize=4)\n",
        "plt.plot(epochs, val_acc, 'r*-', label='Validation accuracy', markersize=4)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "# Annotate the points with their values for accuracy\n",
        "for ep, vac in zip(epochs, val_acc):\n",
        "    plt.annotate(f'{vac:.3f}', xy=(ep, vac), xytext=(ep, vac - 0.04), ha='center', color='r')\n",
        "\n",
        "# Train and validation loss\n",
        "plt.figure()  # Create a new figure for loss plot\n",
        "plt.plot(epochs, loss, 'bo-', label='Training loss', markersize=4)\n",
        "plt.plot(epochs, val_loss, 'r*-', label='Validation loss', markersize=4)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "#plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Calculando la precision\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en la validacion: {scores[1]*100}\")"
      ],
      "metadata": {
        "id": "VecbRMapntFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}